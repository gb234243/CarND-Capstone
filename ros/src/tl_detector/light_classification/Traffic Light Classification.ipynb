{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import yaml\n",
    "import os, os.path, sys, logging\n",
    "from functools import reduce\n",
    "import re, random, scipy.misc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the training/test set information\n",
    "def get_all_labels(input_yaml, riib=False):\n",
    "    \"\"\" Gets all labels within label file\n",
    "    Note that RGB images are 1280x720 and RIIB images are 1280x736.\n",
    "    :param input_yaml: Path to yaml file\n",
    "    :param riib: If True, change path to labeled pictures\n",
    "    :return: images: Labels for traffic lights\n",
    "    \"\"\"\n",
    "    images = yaml.load(open(input_yaml, 'rb').read())\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        images[i]['path'] = os.path.abspath(os.path.join(os.path.dirname(input_yaml), images[i]['path']))\n",
    "        if riib:\n",
    "            images[i]['path'] = images[i]['path'].replace('.png', '.pgm')\n",
    "            images[i]['path'] = images[i]['path'].replace('rgb/train', 'riib/train')\n",
    "            images[i]['path'] = images[i]['path'].replace('rgb/test', 'riib/test')\n",
    "            for box in images[i]['boxes']:\n",
    "                box['y_max'] = box['y_max'] + 8\n",
    "                box['y_min'] = box['y_min'] + 8\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## BOSCH DATASET\n",
    "# train_yaml = \"images/train.yaml\"\n",
    "# test_yaml = \"images/test.yaml\"\n",
    "\n",
    "## SIMULATOR DATASET\n",
    "simulator_yaml = \"simulator/simulator_final.yaml\"\n",
    "dataset = get_all_labels(simulator_yaml)\n",
    "\n",
    "# Split into paths and labels\n",
    "paths = []\n",
    "labels = []\n",
    "for data in dataset:\n",
    "    paths.append(data['path'])\n",
    "    \n",
    "    # Determine label\n",
    "    if len(data['boxes']) == 0:\n",
    "        labels.append('NoLight')\n",
    "    else:\n",
    "        labels.append(data['boxes'][0]['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validation, and test sets\n",
    "# Split ratio is 7:3:1\n",
    "x_train, x_not_train, y_train, y_not_train = train_test_split(paths, labels, test_size=0.3)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_not_train, y_not_train, test_size=0.33)\n",
    "\n",
    "print(\"Train size: {}, Validation size: {}, Test size: {}\".format( \\\n",
    "    len(x_train), len(x_validation), len(x_test))) \n",
    "print(\"All labels in training set:\", set(y_train))\n",
    "print(\"All labels in validation set:\", set(y_validation))\n",
    "print(\"All labels in test set:\", set(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label counts in training set - Needed for oversampling\n",
    "label_counts = {}\n",
    "label_indicies = {}\n",
    "for i, label in enumerate(y_train):\n",
    "    if label not in label_counts:\n",
    "        label_counts[label] = 0\n",
    "        label_indicies[label] = []\n",
    "    label_counts[label] += 1\n",
    "    label_indicies[label].append(i)\n",
    "print(label_counts)\n",
    "print()\n",
    "print(\"Indicies with Yellow label:\", label_indicies['Yellow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversample Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine label seen the most\n",
    "max_count = 0\n",
    "for label in label_counts:\n",
    "    max_count = max(max_count, label_counts[label])\n",
    "\n",
    "# Oversample\n",
    "oversampled_train_indicies = []\n",
    "for label in label_indicies:\n",
    "    random.shuffle(label_indicies[label])\n",
    "    \n",
    "    new_label_set = []\n",
    "    new_label_set += label_indicies[label] * int(max_count / len(label_indicies[label]))\n",
    "    new_label_set += label_indicies[label][0:max_count % len(label_indicies[label])]\n",
    "    \n",
    "    oversampled_train_indicies += new_label_set\n",
    "    print(\"Label {} now has {} indicies\".format(label, len(new_label_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(imgPath):\n",
    "    img = cv2.imread(imgPath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "# One Hot Encoder Mapping\n",
    "label_ohe_map = {\n",
    "    'NoLight': [1, 0, 0, 0],\n",
    "    'Red': [0, 1, 0, 0],\n",
    "    'Yellow': [0, 0, 1, 0], \n",
    "    'Green': [0, 0, 0, 1]\n",
    "}\n",
    "\n",
    "## Create Generator\n",
    "def createBatchGenerator(indicies, x, y):\n",
    "    def batchGenerator(batch_size):\n",
    "        random.shuffle(indicies)\n",
    "        \n",
    "        for batch_i in range(0, len(indicies), batch_size):\n",
    "            images = []\n",
    "            labels = []\n",
    "            \n",
    "            for index in indicies[batch_i:batch_i + batch_size]:\n",
    "                image = np.array(loadImage(x[index]))\n",
    "                image = image / 128 - 1.0 # normalize the image\n",
    "                label = label_ohe_map[y[index]]\n",
    "                \n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "            \n",
    "            yield np.array(images), np.array(labels)\n",
    "        \n",
    "    return batchGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingBatchGenerator = createBatchGenerator(oversampled_train_indicies, x_train, y_train)\n",
    "validationBatchGenerator = createBatchGenerator(list(range(len(x_validation))), x_validation, y_validation)\n",
    "testBatchGenerator = createBatchGenerator(list(range(len(x_test))), x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addConv(input, filters, kernel, stride, padding, keepprob):\n",
    "    conv = tf.layers.conv2d(input, filters, kernel, stride, padding=padding, \\\n",
    "                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.01), \\\n",
    "                            activation=tf.nn.relu)\n",
    "    batch_norm = tf.layers.batch_normalization(conv)\n",
    "    dropout = tf.layers.dropout(batch_norm, keepprob)\n",
    "    \n",
    "    return dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Placeholders\n",
    "images = tf.placeholder(tf.float32, (None, None, None, 3), name='input_images')\n",
    "images_resized = tf.image.resize_images(images, (600, 800))\n",
    "labels = tf.placeholder(tf.float32, (None, 4), name='labels')\n",
    "keepprob = tf.placeholder(tf.float32, name='keep_probability')\n",
    "learningrate = tf.placeholder(tf.float32, name='learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Network (Custom, Ensemble CNN)\n",
    "\n",
    "def createEnsembleCNNUnit(input):\n",
    "    conv1 = addConv(input, 32, 3, 2, 'valid', keepprob)\n",
    "    max1 = tf.layers.max_pooling2d(conv1, 2, 2, padding='valid')\n",
    "\n",
    "    conv2 = addConv(max1, 64, 3, 2, 'valid', keepprob)\n",
    "    max2 = tf.layers.max_pooling2d(conv2, 2, 2, padding='valid')\n",
    "\n",
    "    conv3 = addConv(max2, 128, 3, 2, 'valid', keepprob)\n",
    "    max3 = tf.layers.max_pooling2d(conv3, 2, 2, padding='valid')\n",
    "\n",
    "    conv4 = addConv(max3, 128, 3, 2, 'valid', keepprob)\n",
    "    max4 = tf.layers.max_pooling2d(conv4, 2, 2, padding='valid')\n",
    "\n",
    "    flat = tf.layers.flatten(max4)\n",
    "    fc1 = tf.layers.dense(flat, 128, activation=tf.nn.relu)\n",
    "    fc2 = tf.layers.dense(fc1, 64, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(fc2, 4, activation=tf.nn.relu)\n",
    "    \n",
    "    return logits\n",
    "\n",
    "unit_1 = createEnsembleCNNUnit(images_resized)\n",
    "unit_2 = createEnsembleCNNUnit(images_resized)\n",
    "unit_3 = createEnsembleCNNUnit(images_resized)\n",
    "\n",
    "logits = tf.add(tf.add(unit_1, unit_2), unit_3, name=\"logits\")\n",
    "output = tf.nn.softmax(logits, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Optimizer\n",
    "softmax_losses = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "loss = tf.reduce_mean(softmax_losses)\n",
    "optimizer = tf.train.AdamOptimizer(learningrate).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(labels, 1), tf.argmax(output, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "lr = 1e-5\n",
    "kp = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train Network\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "print(\"Training...\")\n",
    "for e in range(epochs):\n",
    "\n",
    "    # Train Network\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    i = 0\n",
    "    for train_images, train_labels in trainingBatchGenerator(batch_size):\n",
    "        _, loss_val, acc = sess.run([optimizer, loss, accuracy], {images: train_images, labels: train_labels, \\\n",
    "                                               keepprob: kp, learningrate: lr})\n",
    "        total_loss += loss_val\n",
    "        total_accuracy += acc * train_images.shape[0]\n",
    "\n",
    "        # Print iteration information\n",
    "        i += 1\n",
    "        if i % 5 == 0:\n",
    "            print(\"   Iteration Loss: {:.5f}, Iteration Accuracy: {:.2f}%\".format(loss_val, acc * 100))\n",
    "\n",
    "    # Determine Validation Accuracy\n",
    "    validation_loss = 0\n",
    "    validation_acc = 0\n",
    "    for valid_images, valid_labels in validationBatchGenerator(batch_size):\n",
    "        loss_val, acc = sess.run([loss, accuracy], {images: valid_images, labels: valid_labels, keepprob: 1.0})\n",
    "        validation_loss += loss_val\n",
    "        validation_acc += acc * valid_images.shape[0]\n",
    "\n",
    "    print(\"Epoch {}, Training Loss: {:.5f}, Training Accuracy: {:.2f}%, Validation Loss: {:.5f}, Validation Accuracy: {:.2f}%\"\\\n",
    "          .format(e+1, total_loss, total_accuracy * 100 / len(oversampled_train_indicies), \\\n",
    "                 validation_loss, validation_acc * 100 / len(x_validation)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Network\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './models/cnn_ensemble.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, './models/cnn_ensemble.ckpt')\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Accuracy\n",
    "total_loss = 0\n",
    "total_acc = 0\n",
    "\n",
    "for test_images, test_labels in testBatchGenerator(batch_size):\n",
    "    loss_val, acc = sess.run([loss, accuracy], {images: test_images, labels: test_labels, keepprob: 1.0})\n",
    "    total_loss += loss_val\n",
    "    total_acc += acc * test_images.shape[0]\n",
    "\n",
    "print(\"Test Loss: {:.5f}, Accuracy: {:.2f}%\".format(total_loss, total_acc * 100 / len(x_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visually Confirm Working Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ohe_map_reversed = ['NoLight', 'Red', 'Yellow', 'Green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_test_index = 0\n",
    "\n",
    "# Load Image\n",
    "test_img = loadImage(x_test[desired_test_index])\n",
    "plt.imshow(test_img)\n",
    "\n",
    "# Run Classification\n",
    "ohe_index = sess.run(tf.argmax(output, 1), {images: [test_img], keepprob: 1.0})[0]\n",
    "\n",
    "# Print Information   \n",
    "\n",
    "print(\"Network guessed: {}\".format(label_ohe_map_reversed[ohe_index]))\n",
    "print(\"Actual label: {}\".format(y_test[desired_test_index]))\n",
    "if label_ohe_map_reversed[ohe_index] == y_test[desired_test_index]:\n",
    "    print(\"Correct!\")\n",
    "else:\n",
    "    print(\"INCORRECT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze the Graph into a Protobuf File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools.freeze_graph import freeze_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "    \"\"\"Extract the sub graph defined by the output nodes and convert \n",
    "    all its variables into constant \n",
    "    Args:\n",
    "        model_dir: the root folder containing the checkpoint state file\n",
    "        output_node_names: a string, containing all the output node's names, \n",
    "                            comma separated\n",
    "    \"\"\"\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            \"directory: %s\" % model_dir)\n",
    "\n",
    "    if not output_node_names:\n",
    "        print(\"You need to supply the name of a node to --output_node_names.\")\n",
    "        return -1\n",
    "\n",
    "    # We retrieve our checkpoint fullpath\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "    \n",
    "    # We precise the file fullname of our freezed graph\n",
    "    absolute_model_dir = \"/\".join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + \"/frozen_pursuit_model.pb\"\n",
    "\n",
    "    # We clear devices to allow TensorFlow to control on which device it will load operations\n",
    "    clear_devices = True\n",
    "\n",
    "    # We start a session using a temporary fresh Graph\n",
    "    with tf.Session(graph=tf.Graph()) as sess:\n",
    "        # We import the meta graph in the current default Graph\n",
    "        saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
    "\n",
    "        #[print(n.name) for n in tf.get_default_graph().as_graph_def().node]\n",
    "        # We restore the weights\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "\n",
    "        # We use a built-in TF helper to export variables to constants\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess, # The session is used to retrieve the weights\n",
    "            tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "            output_node_names.split(\",\") # The output node names are used to select the usefull nodes\n",
    "        ) \n",
    "\n",
    "        # Finally we serialize and dump the output graph to the filesystem\n",
    "        with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n",
    "\n",
    "    return output_graph_def\n",
    "\n",
    "freeze_graph(\"./models/\", \"input_images, logits, labels, output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
